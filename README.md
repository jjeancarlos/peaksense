# üí° Otimizador de Consumo Energ√©tico

[](https://www.python.org/downloads/)
[](https://streamlit.io)
[](https://xgboost.ai/)

Este √© um projeto *full-stack* de Data Science para previs√£o de demanda energ√©tica no Brasil. O objetivo √© construir um pipeline completo, desde a coleta de dados brutos (web-scraping) at√© um modelo de Machine Learning de alta precis√£o e um dashboard interativo.

O modelo principal **(V4: XGBoost-Only)** alcan√ßou um **Erro Percentual M√©dio (MAPE) de 6.70%** na previs√£o de demanda di√°ria, utilizando um pipeline de features otimizado.

<img width="745" height="905" alt="Image" src="https://github.com/user-attachments/assets/9d826b63-57a1-46ed-9362-6b43c9c09117" />

<img width="1790" height="690" alt="Image" src="https://github.com/user-attachments/assets/0e160a0f-7e3c-4d9e-ad62-504f59892f5e" />



## üöÄ Principais Funcionalidades

  * **Pipeline de ETL:** Scripts para coletar, processar, limpar e harmonizar dados de m√∫ltiplas fontes (INMET, CCEE, IBGE).
  * **Modelo Preditivo (ML):** Um modelo XGBoost (V4) treinado por regi√£o, capaz de prever a demanda energ√©tica (`MWm`) com base em clima, popula√ß√£o e fatores sazonais.
  * **Pipeline de NLP:** Um coletor de not√≠cias (via NewsAPI) com um pipeline de NLP (spaCy) para classificar eventos (ex: "Onda de Calor", "Apag√£o") e fornecer contexto qualitativo.
  * **Dashboard Interativo:** Uma aplica√ß√£o web (`Streamlit`) que carrega os modelos V4 treinados e permite a an√°lise visual das previs√µes.
  * **An√°lise Geoespacial Avan√ßada:** Um notebook de an√°lise (`Projeto_Energia_FINAL.ipynb`) que utiliza dados clim√°ticos completos e `geopandas` para explorar a distribui√ß√£o espacial do clima e seu impacto no consumo.

-----

## üìä Dashboard em A√ß√£o

O dashboard `src/dashboard.py` √© o produto final do pipeline principal, onde os modelos V4 s√£o carregados para um *backtest* visual.

**(Cole um GIF ou screenshot do seu `streamlit run src/dashboard.py` aqui\!)**
`![Demo do Dashboard](caminho/para/seu/screenshot.png)`

-----

## üõ†Ô∏è Stack Tecnol√≥gico

Este projeto utiliza um conjunto de ferramentas modernas de Data Science, conforme definido no `requirements.txt`:

  * **N√∫cleo de Dados e ML:** `pandas`, `numpy`, `scikit-learn`, `xgboost`
  * **S√©ries Temporais:** `prophet`, `cmdstanpy`, `holidays`
  * **Geoprocessamento (Mapas):** `geopandas`, `geobr`
  * **Processamento de Linguagem Natural (PLN / NLP):** `spacy`
  * **Explora√ß√£o, Visualiza√ß√£o e Notebooks:** `jupyter`, `matplotlib`, `seaborn`, `chardet`
  * **Dashboard / Aplica√ß√£o Web:** `streamlit`
  * **Coleta de Dados e APIs:** `requests`
  * **Gerenciamento de Vari√°veis de Ambiente:** `python-dotenv`

-----

## üìÇ Estrutura do Projeto

O projeto segue uma estrutura de Data Science padr√£o, separando dados, notebooks e scripts de produ√ß√£o.

```bash
peaksense/
‚îú‚îÄ‚îÄ .env                  # [SECRETO] Armazena a API Key 
‚îú‚îÄ‚îÄ .gitignore            # Ignora arquivos de ambiente, dados e modelos
‚îú‚îÄ‚îÄ README.md             # Este arquivo
‚îú‚îÄ‚îÄ requirements.txt      # Lista de depend√™ncias do projeto
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Dados brutos (CSVs originais, not√≠cias_raw.csv, dados INMET completos)
‚îÇ   ‚îú‚îÄ‚îÄ processed/        # Dados limpos para o pipeline principal (master_dataset.csv)
‚îÇ   ‚îî‚îÄ‚îÄ models/           # Modelos XGBoost (V4) treinados e salvos (.json)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/            # Notebooks Jupyter para explora√ß√£o e avalia√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ eda.ipynb         # (Caminho A) An√°lise Explorat√≥ria (Objetivos A, B, C)
‚îÇ   ‚îú‚îÄ‚îÄ model_evaluation.ipynb # (Caminho A) A jornada de V1 a V4 (Provas de Modelo)
‚îÇ   ‚îú‚îÄ‚îÄ nlp_analysis.ipynb     # (Caminho A) Pipeline de NLP com spaCy
‚îÇ   ‚îî‚îÄ‚îÄ Projeto_Energia_FINAL.ipynb # (Caminho B) An√°lise avan√ßada com Geopandas e dados completos
‚îÇ
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ data_collection.py     # (Caminho A) Coleta not√≠cias da NewsAPI
    ‚îú‚îÄ‚îÄ data_processing.py     # (Caminho A) Limpa e junta os 3 CSVs -> master_dataset.csv
    ‚îú‚îÄ‚îÄ ml_pipeline.py         # (Caminho A) Treina o modelo V4 e salva em /data/models
    ‚îî‚îÄ‚îÄ dashboard.py           # (Caminho A) Roda o dashboard Streamlit
```

-----

## ‚öôÔ∏è Instala√ß√£o e Execu√ß√£o

Siga estes passos para configurar e rodar o projeto localmente.

### 1\. Pr√©-requisitos

  * Python 3.10 ou superior
  * Chave de API gratuita da [NewsAPI.org](https://newsapi.org/) (necess√°ria para o pipeline de NLP)

### 2\. Instala√ß√£o

```bash
# 1. Clone o reposit√≥rio
git clone https://github.com/seu-usuario/peaksense.git
cd peaksense

# 2. Crie e ative um ambiente virtual
python -m venv venv
source venv/bin/activate  # (Linux/Mac)
# .\venv\Scripts\activate  # (Windows)

# 3. Instale todas as depend√™ncias do Python
# (Isso pode levar algum tempo devido ao geopandas e prophet)
pip install -r requirements.txt

# 4. Baixe o modelo de linguagem treinado para o portugu√™s (do spaCy)
python -m spacy download pt_core_news_lg
```

### 3\. Configura√ß√£o de Seguran√ßa (API Key)

Este √© um passo **crucial** para proteger sua chave de API (usada pelo `data_collection.py`).

1.  Crie um arquivo chamado `.env` na raiz do projeto (`peaksense/.env`).
2.  Abra o arquivo e cole sua chave de API da NewsAPI:
    ```bash
    API_KEY="sua_chave_real_da_newsapi_aqui"
    ```
3.  O arquivo `.gitignore` j√° est√° configurado para **nunca** enviar seu `.env` para o GitHub.

-----

## üöÄ Modo de Uso (Dois Caminhos)

Este projeto oferece dois caminhos de an√°lise:

### Caminho A: Pipeline de Produ√ß√£o (Modelo V4 + Dashboard)

Execute os scripts na ordem correta para popular os dados, treinar o modelo e iniciar o dashboard.

**Certifique-se de que seu ambiente virtual (`venv`) est√° ativado para todos os passos.**

```bash
# PASSO 1: Processar Dados de ML (Obrigat√≥rio)
# L√™ os 3 CSVs b√°sicos de /raw, limpa, junta e salva em data/processed/master_dataset.csv
python src/data_processing.py

# PASSO 2: Treinar o Modelo Final (Obrigat√≥rio)
# Carrega o master_dataset.csv, treina os 4 modelos (V4) e salva em /data/models/
python src/ml_pipeline.py

# PASSO 3: Iniciar o Dashboard (O Produto Final)
# Inicia a aplica√ß√£o web localmente
streamlit run src/dashboard.py
```

Acesse `http://localhost:8501` no seu navegador para ver o dashboard.

### Caminho B: An√°lise Geoespacial Avan√ßada (Notebook B√¥nus)

Este caminho usa um conjunto de dados clim√°ticos mais completo e n√£o est√° conectado ao pipeline principal do dashboard.

1.  **Baixe os Dados:** Fa√ßa o download dos dados clim√°ticos completos do INMET [neste link do Google Drive](https://drive.google.com/drive/folders/19UBBJoI2rACpZB1SK68ZeWd5aAH37Nzg?usp=sharing).
2.  **Organize os Arquivos:** Coloque os arquivos baixados na pasta `data/raw/` (ou atualize os caminhos dentro do notebook).
3.  **Execute o Notebook:** Abra e execute as c√©lulas do `notebooks/Projeto_Energia_FINAL.ipynb` usando o Jupyter.

-----

## üåç Fontes dos Dados

Os dados brutos para este projeto foram obtidos de fontes p√∫blicas oficiais brasileiras:

  * **Dados Clim√°ticos (Pipeline Principal):** [INMET - Instituto Nacional de Meteorologia](https://bdmep.inmet.gov.br/)
  * **Dados Clim√°ticos (An√°lise Geoespacial):** [Dataset INMET Compilado (via Google Drive)](https://drive.google.com/drive/folders/19UBBJoI2rACpZB1SK68ZeWd5aAH37Nzg?usp=sharing)
  * **Consumo de Energia:** [CCEE - C√¢mara de Comercializa√ß√£o de Energia El√©trica](https://www.ccee.org.br/)
  * **Dados Populacionais:** [IBGE - Instituto Brasileiro de Geografia e Estat√≠stica](https://www.ibge.gov.br/)
  * **Dados de Not√≠cias (NLP):** [NewsAPI.org](https://newsapi.org/)

-----

## üî¨ Metodologia e Descobertas Chave

A an√°lise completa est√° nos notebooks (`/notebooks`), mas os principais insights s√£o:

### 1\. An√°lise Explorat√≥ria (Objetivos A e B)

  * **Consumo √ó Popula√ß√£o (A):** Hip√≥tese **confirmada**. A correla√ß√£o entre Popula√ß√£o e Consumo total √© de **0.96**.
  * **Consumo √ó Clima (B):** Hip√≥tese **confirmada (com nuances)**. O clima tem um impacto *n√£o-linear* e *regional*:
      * **Regi√£o Sul:** Mais frio = Mais consumo (efeito de aquecedores).
      * **Regi√£o Sudeste/CO:** Mais calor = Mais consumo (efeito de ar-condicionado).

### 2\. A Jornada do Modelo (V1 ‚Üí V4)

O modelo final do pipeline (V4) foi escolhido ap√≥s um processo rigoroso de avalia√ß√£o (ver `model_evaluation.ipynb`):

  * **V1 (Prophet + Clima):** `FALHOU` (MAPE \> 1000%). O Prophet **extrapolou** os regressores de clima.
  * **V2/V3 (H√≠brido Prophet + XGBoost):** `FALHOU`. Arquitetura inst√°vel que previu consumo *negativo*.
  * **V4 (XGBoost-Only):** `SUCESSO!` (MAPE 6.70%). Um √∫nico modelo XGBoost (treinado por regi√£o) provou ser robusto e aprendeu as regras n√£o-lineares do clima.

### 3\. Resultados Finais (V4: XGBoost-Only)

| Regi√£o | Erro M√©dio (MAPE) | Erro M√©dio (MAE) |
| :--- | :---: | :---: |
| Nordeste | 5.04 % | 410.73 MWm |
| Norte | 5.54 % | 219.38 MWm |
| Sudeste/CO | 7.38 % | 1649.37 MWm |
| Sul | 8.85 % | 605.41 MWm |
| **GLOBAL (Agregado)** | **6.70 %** | **721.22 MWm** |

### 4\. Pipeline de NLP (Contexto Qualitativo)

O pipeline de NLP (`nlp_analysis.ipynb`) provou ser eficaz em filtrar "ru√≠do" (94% das not√≠cias) e identificar eventos reais, como **"alertas de tempestade do Inmet"**, fornecendo um contexto valioso para explicar picos de erro no modelo de ML.

### 5\. An√°lise B√¥nus: Geoprocessamento (`Projeto_Energia_FINAL.ipynb`)

Este notebook paralelo utiliza os dados clim√°ticos completos do INMET e as bibliotecas `geopandas`/`geobr` para criar uma an√°lise geoespacial. Ele explora como as vari√°veis clim√°ticas (temperatura, precipita√ß√£o) se distribuem *espacialmente* pelo Brasil e como isso se correlaciona com os centros de consumo regionais, enriquecendo a an√°lise explorat√≥ria.

## üë§ Autores
  * [Jean Carlos](https://github.com/jjeancarlos)
  * [Matheus Menezes](https://github.com/MatheusLuv)
  * [Tiago Elias](https://github.com/TiagosailE)

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.
