# üí° Otimizador de Consumo Energ√©tico

[](https://www.python.org/downloads/)
[](https://streamlit.io)
[](https://xgboost.ai/)

Este √© um projeto *full-stack* de Data Science para previs√£o de demanda energ√©tica no Brasil. O objetivo √© construir um pipeline completo, desde a coleta de dados brutos (web-scraping) at√© um modelo de Machine Learning de alta precis√£o e um dashboard interativo para consumo dos resultados.

O modelo final **(V4: XGBoost-Only)** alcan√ßou um **Erro Percentual M√©dio (MAPE) de 6.70%** na previs√£o de demanda di√°ria, com performance robusta em todas as regi√µes do pa√≠s.

-----

## üöÄ Principais Funcionalidades

  * **Pipeline de ETL:** Scripts para coletar, processar, limpar e harmonizar dados de m√∫ltiplas fontes (INMET, CCEE, IBGE).
  * **Modelo Preditivo (ML):** Um modelo XGBoost treinado por regi√£o, capaz de prever a demanda energ√©tica (`MWm`) com base em clima, popula√ß√£o e fatores sazonais.
  * **Pipeline de NLP:** Um coletor de not√≠cias (via NewsAPI) com um pipeline de NLP (spaCy) para classificar eventos (ex: "Onda de Calor", "Apag√£o") e fornecer contexto qualitativo para anomalias no consumo.
  * **Dashboard Interativo:** Uma aplica√ß√£o web (`Streamlit`) que carrega os modelos treinados e permite a an√°lise visual das previs√µes contra os dados reais.

-----

## üìä Dashboard em A√ß√£o

O dashboard `src/dashboard.py` √© o produto final do projeto, onde os modelos treinados s√£o carregados e usados para um *backtest* visual.

## üõ†Ô∏è Stack Tecnol√≥gico

Este projeto utiliza um conjunto de ferramentas modernas de Data Science:

  * **Manipula√ß√£o de Dados:** `pandas`, `numpy`
  * **Machine Learning:** `scikit-learn` (M√©tricas), `xgboost` (Modelo V4), `prophet` (Testes V1-V3)
  * **Coleta de Dados & NLP:** `requests` (API), `python-dotenv` (Seguran√ßa), `spacy` (pt\_core\_news\_lg)
  * **Engenharia de Features:** `holidays` (Feriados)
  * **Visualiza√ß√£o & Dashboard:** `matplotlib`, `seaborn`, `streamlit`
  * **Ambiente & Notebooks:** `venv`, `jupyter`, `notebook`

-----

## üìÇ Estrutura do Projeto

O projeto segue uma estrutura de Data Science padr√£o, separando dados brutos, processados, notebooks de explora√ß√£o e scripts de produ√ß√£o.

```bash
peaksense/
‚îú‚îÄ‚îÄ .env                  # [SECRETO] Armazena a API Key (ignorado pelo Git)
‚îú‚îÄ‚îÄ .gitignore            # Ignora arquivos de ambiente, dados e modelos
‚îú‚îÄ‚îÄ README.md             # Este arquivo
‚îú‚îÄ‚îÄ requirements.txt      # Lista de depend√™ncias do projeto
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Dados brutos (CSVs originais, not√≠cias_raw.csv)
‚îÇ   ‚îî‚îÄ‚îÄ processed/        # Dados limpos e prontos para ML (master_dataset.csv)
‚îÇ
‚îú‚îÄ‚îÄ models/               # Modelos XGBoost treinados e salvos (.json)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/            # Notebooks Jupyter para explora√ß√£o e avalia√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ eda.ipynb         # An√°lise Explorat√≥ria (Objetivos A, B, C)
‚îÇ   ‚îú‚îÄ‚îÄ model_evaluation.ipynb # A jornada de V1 a V4 (Provas de Modelo)
‚îÇ   ‚îî‚îÄ‚îÄ nlp_analysis.ipynb     # Pipeline de NLP com spaCy
‚îÇ
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ data_collection.py     # (NLP) Coleta not√≠cias da NewsAPI
    ‚îú‚îÄ‚îÄ data_processing.py     # (ETL) Limpa e junta os 3 CSVs -> master_dataset.csv
    ‚îú‚îÄ‚îÄ ml_pipeline.py         # (ML) Treina o modelo V4 e salva em /models
    ‚îî‚îÄ‚îÄ dashboard.py           # (App) Roda o dashboard Streamlit
```

-----

## ‚öôÔ∏è Instala√ß√£o e Execu√ß√£o

Siga estes passos para configurar e rodar o projeto localmente.

### 1\. Pr√©-requisitos

  * Python 3.10 ou superior
  * Chave de API gratuita da [NewsAPI.org](https://newsapi.org/) (necess√°ria para o pipeline de NLP)

### 2\. Instala√ß√£o

```bash
# 1. Clone o reposit√≥rio
git clone https://github.com/seu-usuario/peaksense.git
cd peaksense

# 2. Crie e ative um ambiente virtual
python -m venv venv
source venv/bin/activate  # (Linux/Mac)
.\venv\Scripts\activate  # (Windows)

# 3.modelo de linguagem treinado para o portugu√™s
python -m spacy download pt_core_news_lg

# 4. Instale todas as depend√™ncias
pip install -r requirements.txt
```

### 3\. Configura√ß√£o de Seguran√ßa (API Key)

Este √© um passo **crucial** para proteger sua chave de API.

1.  Crie um arquivo chamado `.env` na raiz do projeto (`peaksense/.env`).
2.  Abra o arquivo e cole sua chave de API da NewsAPI:

    ```bash
    API_KEY="sua_chave_real_da_newsapi_aqui"
    ```
3.  O arquivo `.gitignore` j√° est√° configurado para **nunca** enviar seu `.env` para o GitHub.

-----

## üöÄ Modo de Uso (Executando o Pipeline)

Execute os scripts na ordem correta para popular os dados, treinar o modelo e iniciar o dashboard.

**Certifique-se de que seu ambiente virtual (`venv`) est√° ativado para todos os passos.**

### Passo 1: Coletar Dados de NLP

(Opcional, mas necess√°rio para o `nlp_analysis.ipynb`)

```bash
# Busca not√≠cias recentes e salva em data/raw/noticias_energia_raw.csv
python src/data_collection.py
```

### Passo 2: Processar Dados de ML

(Obrigat√≥rio)

```bash
# L√™ os 3 CSVs de /raw, limpa, junta e salva em data/processed/master_dataset.csv
python src/data_processing.py
```

### Passo 3: Treinar o Modelo Final

(Obrigat√≥rio)

```bash
# Carrega o master_dataset.csv, treina os 4 modelos (V4) e salva em /models/
python src/ml_pipeline.py
```

### Passo 4: Iniciar o Dashboard

(O Produto Final)

```bash
# Inicia a aplica√ß√£o web localmente
streamlit run src/dashboard.py
```

Acesse `http://localhost:8501` no seu navegador para ver o dashboard.

-----

## üåç Fontes dos Dados

Os dados brutos para este projeto foram obtidos de fontes p√∫blicas oficiais brasileiras:

  * **Dados Clim√°ticos:** [INMET - Instituto Nacional de Meteorologia](https://bdmep.inmet.gov.br/)
  * **Consumo de Energia:** [CCEE - C√¢mara de Comercializa√ß√£o de Energia El√©trica](https://www.ccee.org.br/)
  * **Dados Populacionais:** [IBGE - Instituto Brasileiro de Geografia e Estat√≠stica](https://www.ibge.gov.br/)
  * **Dados de Not√≠cias (NLP):** [NewsAPI.org](https://newsapi.org/)

-----

## üî¨ Metodologia e Descobertas Chave

A an√°lise completa est√° nos notebooks (`/notebooks`), mas os principais insights s√£o:

### 1\. An√°lise Explorat√≥ria (Objetivos A e B)

  * **Consumo √ó Popula√ß√£o (A):** Hip√≥tese **confirmada**. A correla√ß√£o entre Popula√ß√£o e Consumo total √© de **0.96**, provando ser o driver macro mais importante.
  * **Consumo √ó Clima (B):** Hip√≥tese **confirmada (com nuances)**. O clima tem um impacto *n√£o-linear* e *regional*:
      * **Regi√£o Sul:** Mais frio = Mais consumo (efeito de aquecedores).
      * **Regi√£o Sudeste/CO:** Mais calor = Mais consumo (efeito de ar-condicionado).

### 2\. A Jornada do Modelo (V1 ‚Üí V4)

O modelo final (V4) foi escolhido ap√≥s um processo rigoroso de avalia√ß√£o (ver `model_evaluation.ipynb`):

  * **V1 (Prophet + Clima):** `FALHOU` (MAPE \> 1000%). O Prophet **extrapolou** os regressores de clima, prevendo valores absurdos.
  * **V2/V3 (H√≠brido Prophet + XGBoost nos Res√≠duos):** `FALHOU`. Arquitetura inst√°vel que previu consumo *negativo* e padr√µes invertidos.
  * **V4 (XGBoost-Only):** `SUCESSO!` (MAPE 6.70%). Um √∫nico modelo XGBoost (treinado por regi√£o) provou ser robusto, aprendeu as regras n√£o-lineares do clima e n√£o sofreu de extrapola√ß√£o.

### 3\. Resultados Finais (V4: XGBoost-Only)

| Regi√£o | Erro M√©dio (MAPE) | Erro M√©dio (MAE) |
| :--- | :---: | :---: |
| Nordeste | 5.04 % | 410.73 MWm |
| Norte | 5.54 % | 219.38 MWm |
| Sudeste/CO | 7.38 % | 1649.37 MWm |
| Sul | 8.85 % | 605.41 MWm |
| **GLOBAL (Agregado)** | **6.70 %** | **721.22 MWm** |

### 4\. Pipeline de NLP (Contexto Qualitativo)

O pipeline de NLP (`nlp_analysis.ipynb`) provou ser eficaz em filtrar "ru√≠do" (94% das not√≠cias) e identificar eventos reais, como **"alertas de tempestade do Inmet"**, fornecendo um contexto valioso para explicar picos de erro no modelo de ML.

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.